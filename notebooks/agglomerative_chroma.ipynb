{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings from ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_beat_grid(beats: np.ndarray, tempo: float, sr: int, hop_length: int, duration: float, unit: str = 'time') -> np.ndarray:\n",
    "    \"\"\"Generate beat grid within the duration of a song. Returns beat grid in time units\"\"\"\n",
    "    first_beat_time = librosa.frames_to_time(beats[0], sr=sr, hop_length=hop_length)\n",
    "    seconds_per_beat = 60.0 / tempo\n",
    "    num_beats_forward = int((duration - first_beat_time) / seconds_per_beat)\n",
    "    num_beats_backward = int(first_beat_time / seconds_per_beat) + 1\n",
    "    beat_times_forward = first_beat_time + np.arange(num_beats_forward) * seconds_per_beat\n",
    "    beat_times_backward = first_beat_time - np.arange(1, num_beats_backward) * seconds_per_beat\n",
    "    beat_grid = np.concatenate((np.array([0.0]), beat_times_backward[::-1], beat_times_forward))\n",
    "    if unit == 'frames':\n",
    "        beat_grid = librosa.time_to_frames(beat_grid, sr=sr, hop_length=hop_length)\n",
    "    return beat_grid\n",
    "\n",
    "def beat_sync(y: np.ndarray, feature: np.ndarray, sr: int, hop_length: int, time_signature: int = 4) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Sync the features to a beat grid.\"\"\"\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr, hop_length=hop_length)\n",
    "    beat_grid = create_beat_grid(beats, sr=sr, hop_length=hop_length, tempo=tempo, duration=duration)\n",
    "    beat_frames = librosa.util.fix_frames(librosa.time_to_frames(beat_grid, sr=sr, hop_length=hop_length))\n",
    "    feature_beat_synced = librosa.util.sync(feature, librosa.time_to_frames(beat_grid, sr=sr, hop_length=hop_length), aggregate=np.mean)\n",
    "    print(f\"Audio features beat-synchronized. Tempo: {tempo:.2f} BPM.\")\n",
    "    return feature_beat_synced, beat_frames\n",
    "\n",
    "def find_optimal_n_components(X, random_state=None, plot_reconstruction_error=False):\n",
    "    \"\"\"\n",
    "    Find the optimal number of components for NMF by minimizing the reconstruction error with a penalty term.\n",
    "    Plots the reconstruction error and the score (reconstruction error + penalty) \n",
    "    over different values of n_components.\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    max_components = n_features\n",
    "    reconstruction_errors = []\n",
    "    scores = []\n",
    "    \n",
    "    # Calculate the penalty weight\n",
    "    nmf = NMF(n_components=1, random_state=random_state, max_iter=5000, init='nndsvd')\n",
    "    W = nmf.fit_transform(X)\n",
    "    H = nmf.components_\n",
    "    X_approx = W @ H\n",
    "    reconstruction_error_1 = np.sum((X - X_approx) ** 2)\n",
    "    penalty_weight = np.abs(reconstruction_error_1 / max_components)\n",
    "    \n",
    "    for n_components in range(1, max_components + 1):\n",
    "        nmf = NMF(n_components=n_components, random_state=random_state, max_iter=5000, init='nndsvd')\n",
    "        W = nmf.fit_transform(X)\n",
    "        H = nmf.components_\n",
    "        X_approx = W @ H\n",
    "        reconstruction_error = np.sum((X - X_approx) ** 2)\n",
    "        penalty = n_components * penalty_weight\n",
    "        score = reconstruction_error + penalty\n",
    "        reconstruction_errors.append(reconstruction_error)\n",
    "        scores.append(score)\n",
    "        \n",
    "    # Plot reconstruction error and score over n_components\n",
    "    if plot_reconstruction_error == True:\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "        \n",
    "        ax1.plot(range(1, max_components + 1), reconstruction_errors)\n",
    "        ax1.set_xlabel('Number of Components')\n",
    "        ax1.set_ylabel('Reconstruction Error')\n",
    "        ax1.set_title('Reconstruction Error vs. Number of Components')\n",
    "        \n",
    "        ax2.plot(range(1, max_components + 1), scores)\n",
    "        ax2.set_xlabel('Number of Components')\n",
    "        ax2.set_ylabel('Score (Reconstruction Error + Penalty)')\n",
    "        ax2.set_title('Score vs. Number of Components')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Find the optimal number of components\n",
    "    optimal_n_components = np.argmin(scores) + 1\n",
    "    # print(f\"Optimal number of components: {optimal_n_components}\")\n",
    "    \n",
    "    return optimal_n_components\n",
    "\n",
    "def process_bound_times(bounds, beat_grid_times, duration):\n",
    "    \"\"\"\n",
    "    Process the bounds indices and convert them to times using beat_grid_times.\n",
    "    Include 0.0 as the starting time and the song duration as the ending time.\n",
    "    Remove the second bound if the first bound is 0 and the difference between the first and second bounds is <= 7.\n",
    "    If the difference between the last and second-to-last bound times is <= 8, merge the last bound with the second-to-last bound.\n",
    "    \"\"\"\n",
    "    # Remove the second bound if the first bound is 0 and the difference between the first and second bounds is <= 7\n",
    "    if bounds[0] == 0 and bounds[1] - bounds[0] <= 7:\n",
    "        bounds = bounds[:1] + bounds[2:]\n",
    "\n",
    "    # Convert bounds indices to times\n",
    "    bound_times = [beat_grid_times[idx] for idx in bounds]\n",
    "\n",
    "    # Include 0.0 as the starting time and the song duration as the ending time\n",
    "    if bound_times[0] != 0:\n",
    "        bound_times = [0.0] + bound_times + [duration]\n",
    "    else:\n",
    "        bound_times = bound_times + [duration]\n",
    "\n",
    "    # Merge the last bound with the second-to-last bound if the difference between them is <= 8\n",
    "    if len(bound_times) > 2 and bound_times[-1] - bound_times[-2] <= 8:\n",
    "        bound_times = bound_times[:-2] + bound_times[-1:]\n",
    "\n",
    "    return bound_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f83ba2c9c1040d7811ca6092a2912cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing songs:   0%|          | 0/332 [00:00<?, ?song/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Constants\n",
    "hop_length = 128 \n",
    "sr = 12000\n",
    "df = pd.read_csv('../data/clean_labeled.csv') \n",
    "segment_data = []\n",
    "\n",
    "progress_bar = tqdm(df[\"SongID\"].unique(), desc=\"Processing songs\", unit=\"song\", leave=True)\n",
    "for song_id in progress_bar:\n",
    "    # Load audio and extract features\n",
    "    audio_file = f'../data/audio/{song_id}.mp3'\n",
    "    y, _ = librosa.load(audio_file, sr=sr)\n",
    "    y_harm, y_perc = librosa.effects.hpss(y)\n",
    "    onset_env = librosa.onset.onset_strength(y=y_perc, sr=sr, hop_length=hop_length)\n",
    "    duration = librosa.get_duration(y=y_perc, sr=sr)\n",
    "    tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr, hop_length=hop_length)\n",
    "    beat_grid_frames = create_beat_grid(beats, sr=sr, hop_length=hop_length, tempo=tempo, duration=duration, unit='frames')\n",
    "    beat_grid_times = create_beat_grid(beats, sr=sr, hop_length=hop_length, tempo=tempo, duration=duration, unit='time')\n",
    "\n",
    "    # Extract segmentation bounds for normal chromagram\n",
    "    chromagram = librosa.feature.chroma_cqt(y=y_harm, sr=sr, hop_length=hop_length, bins_per_octave=24)\n",
    "    chroma_sync = librosa.util.sync(chromagram, beat_grid_frames, aggregate=np.mean)\n",
    "    chroma_sync = MinMaxScaler().fit_transform(chroma_sync.T).T\n",
    "    optimal_n_components = find_optimal_n_components(chroma_sync.T, plot_reconstruction_error=False)\n",
    "    nmf = NMF(n_components=optimal_n_components, max_iter=5000, init='nndsvd')\n",
    "    chroma_acts = nmf.fit_transform(chroma_sync.T).T\n",
    "    chroma_acts = (chroma_acts - chroma_acts.min(axis=1, keepdims=True)) / (chroma_acts.max(axis=1, keepdims=True) - chroma_acts.min(axis=1, keepdims=True))\n",
    "    bounds_chroma_acts = librosa.segment.agglomerative(chroma_acts, 9)\n",
    "\n",
    "    # Extract bound times\n",
    "    bound_times_chroma_acts = process_bound_times(bounds_chroma_acts, beat_grid_times, duration)\n",
    "\n",
    "    # Create segments\n",
    "    for segment_num, (start, end) in enumerate(zip(bound_times_chroma_acts[:-1], bound_times_chroma_acts[1:]), start=1):\n",
    "        start_beat_idx = np.argmin(np.abs(beat_grid_times - start))\n",
    "        end_beat_idx = np.argmin(np.abs(beat_grid_times - end))\n",
    "        segment_data.append({\n",
    "            'SongID': song_id,\n",
    "            'segment_num': segment_num,\n",
    "            'segment_start': start,\n",
    "            'segment_end': end,\n",
    "            'duration': end - start,\n",
    "            'start_beat_idx': start_beat_idx,\n",
    "            'end_beat_idx': end_beat_idx,\n",
    "            'num_beats': end_beat_idx - start_beat_idx,\n",
    "            'num_components': optimal_n_components,\n",
    "            'seg_type': 'chroma_acts'\n",
    "        })\n",
    "\n",
    "df_segments = pd.DataFrame(segment_data)\n",
    "df_segments.to_csv('../data/agglom_chroma_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
